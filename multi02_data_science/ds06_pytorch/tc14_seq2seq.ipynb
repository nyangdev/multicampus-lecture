{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f84903a7",
   "metadata": {},
   "source": [
    "# Seq 2 Seq (Sequence to Sequence)\n",
    "\n",
    "- input sequence 를 가지고 output sequence 를 생성\n",
    "\n",
    "- 구조\n",
    "\n",
    "    Encoder : input sequence를 RNN (LSTM, GRU 등) 으로 처리 -> context vector 생성\n",
    "\n",
    "    Decoder : Encoder가 전달해준 context vector를 가지고 output sequence 생성 -> Encoder와 마찬가지로 RNN (LSTM, GRU 등) 을 통해 번역된 문장 생성\n",
    "\n",
    "    * Context Vector : input sequence 의 모든 정보를 고정된 길이의 vector로 압축 (= input sequence 요약)\n",
    "\n",
    "- Teacher Forcing : 기존 RNN - Decoder의 output을 다음 timestep의 Decoder 입력으로 사용 => seq2seq - output 대신 실제 정답(label) 을 다음 timestep의 Decoder 입력으로 사용\n",
    "\n",
    "\n",
    "- token 종류\n",
    "\n",
    "    SOS_TOKEN (Start of Sentence Token) : 문장의 시작\n",
    "\n",
    "    EOS_TOKEN (End of Sentence Token) : 문장의 끝\n",
    "\n",
    "    PAD_TOKEN (Padding Token) : input sequence 길이를 맞추기 위해 (비어있는 부분을 PAD_TOEN 이 채움)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8b153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Module, Embedding, GRU, Dropout, Linear, CrossEntropyLoss, init, utils\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import random\n",
    "from time import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c82fbd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "elif torch.xpu.is_available():\n",
    "    device = torch.device(\"xpu\")\n",
    "\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "\n",
    "else: \n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "944c4289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "</s>\n",
      "<pad>\n"
     ]
    }
   ],
   "source": [
    "# dataset load (wmt16의 독일어-영어)\n",
    "# wmt16 :Workshop on statistical Machine Translation 2016 에서 사용된 기계 번역 데이터셋\n",
    "# plit=\"train[:1%]\" : 1%만 load (데이터셋이 너무 많아서)\n",
    "raw_datasets = load_dataset(\"wmt16\", \"de-en\", split=\"train[:1%]\")\n",
    "\n",
    "# tokenizer load (학습 속도를 위해 작은 모델 사용) -> huggingface 에서 이미 학습되어있는 모델의 tokenizer 가져옴\n",
    "# 영어-독일어\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "105ebc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    # English : input sequence (encoder input)\n",
    "    # [ex['en'] for ex in examples['translation']] : 영어 문장들만 뽑아서 list로 만들고,\n",
    "    # max_length=64 : 최대 길이를 정하고,\n",
    "    # truncation=True : 최대 길이를 넘으면 자르고,\n",
    "    # padding=\"max_length\" : 최대 길이보다 작으면 패딩 추가\n",
    "    tokenized_en = tokenizer(\n",
    "        [ex['en'] for ex in examples['translation']],\n",
    "        max_length=64,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    # German : output sequen ce (decoder output)\n",
    "    tokenized_de = tokenizer(\n",
    "        [ex['de'] for ex in examples['translation']],\n",
    "        max_length=64,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    # input_ids : 영어 token들의 id\n",
    "    # attention_mask : 패딩 부분은 무시 (패딩은 0, 아니면 1)\n",
    "    # labels : 독일어 token들의 id\n",
    "    return {\n",
    "        'input_ids': tokenized_en['input_ids'],\n",
    "        'attention_mask': tokenized_en['attention_mask'],\n",
    "        'labels': tokenized_de['input_ids']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17ba7317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize_function 을 사용해서 datasets 정제\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "# pytorch type으로 format 변환\n",
    "tokenized_datasets.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# train_test_split (90 : 10)\n",
    "train_test_split = tokenized_datasets.train_test_split(test_size=0.1)\n",
    "train_data = train_test_split['train']\n",
    "valid_data = train_test_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d31e0893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 설정\n",
    "batch_size = 64\n",
    "train_iterator = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_iterator = DataLoader(valid_data, batch_size=batch_size)\n",
    "\n",
    "# 단어장 크기\n",
    "input_dim = tokenizer.vocab_size\n",
    "output_dim = tokenizer.vocab_size\n",
    "\n",
    "# sequence 의 길이를 맞추기 위해 + padding token 은 무시하기 위해\n",
    "pad_idx = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f05d756",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        # hidden dimention\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # embedding layer : input_dim 갯수의 단어들을 embedding_dim 의 차원을 가진 vector로 변환\n",
    "        self.embedding = Embedding(input_dim, embedding_dim)\n",
    "        \n",
    "        # rnn layer : GRU 사용 \n",
    "        # hidden_dim: vector의 크기\n",
    "        # n_layers : gru layer의 갯수\n",
    "        # batch_first : input tensor의 첫번재 차원\n",
    "        self.rnn = GRU(embedding_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n",
    "        \n",
    "        self.dropout = Dropout(dropout)\n",
    "        \n",
    "    # src : source sequence (= input sequence)\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        # output : Tensor(batch_size, seq_len, hidden_dim) -> embedding 된 input sequence의 GRU 결과 \n",
    "        # => 지금은 사용되지 않으나, attention model로 발전되면 사용됨\n",
    "        # hidden : Tensor(n_layers, batch_size, hidden_dim) -> 마지막에 update 된 timestep의 상태 (state)\n",
    "        output, hidden = self.rnn(embedded) \n",
    "        \n",
    "        # encoder의 최종 hidden tensor를 decoder로 전달\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3306955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Module):\n",
    "    def __init__(self, output_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = Embedding(output_dim, embedding_dim)\n",
    "        \n",
    "        # GRU\n",
    "        self.rnn = GRU(embedding_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n",
    "\n",
    "        # fully connected layer -> output        \n",
    "        self.fc_out = Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = Dropout(dropout)\n",
    "        \n",
    "    # input = [batch size] -> decoder의 현재 시점 입력\n",
    "    # hidden = [n layers * n directions, batch size, hidden_dim] -> encoder output / 이전 시점 decoder 상태\n",
    "    def forward(self, input, hidden):\n",
    "\n",
    "        # [batch size] -> [batch size, 1]로 차원 변경 (rnn 입력 형식에 맞게) -> 각 배치에서, 현재 시점의, 하나의 단어만 입력\n",
    "        input = input.unsqueeze(1) \n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        # output : 현재 시점의 predict 계산 -> 다음 시점의 decoder로 전달\n",
    "        # hidden : 이전 hidden + 현재 입력 -> 현재 hidden\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        \n",
    "        # output을 가지고 예측한 결과\n",
    "        predict = self.fc_out(output.squeeze(1))\n",
    "        \n",
    "        # predict = [batch size, output dim] (vocab size)\n",
    "        return predict, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4ab4510",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    # src : source sequence (영어)\n",
    "    # trg : target sequence (독일어)\n",
    "    # teacher_forcing_ratio = 0.5 : 50% 의 확률로 실제 label을 사용 (나머지 50%는 decoder의 출력-predict- 사용)\n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "\n",
    "        batch_size = trg.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(device)\n",
    "        \n",
    "        hidden = self.encoder(src)\n",
    "        \n",
    "        # decoder의 첫 입력은 <sos> token\n",
    "        # trg의 첫 열은 <sos> token이 있는 열로 가정 (hugging face tokenizer 에서 처리됨)\n",
    "        # trg의 0번째 컬럼 (<sos> token)\n",
    "        input = trg[:, 0]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden = self.decoder(input, hidden)\n",
    "            \n",
    "            # t-1 시점의 predict\n",
    "            outputs[:, t] = output\n",
    "            \n",
    "            # predict 한 결과 token의 id\n",
    "            top1 = output.argmax(1) \n",
    "            \n",
    "            # teacher forcing 적용 여부 결정\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            # 다음 input token 설정: \n",
    "            # teacher forcing (trg[:, t]) 또는 모델 예측 (top1)\n",
    "            input = trg[:, t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbf7418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "hidden_dim = 1024\n",
    "n_layers = 3\n",
    "dropout = 0.3\n",
    "\n",
    "enc = Encoder(input_dim, embedding_dim, hidden_dim, n_layers, dropout)\n",
    "dec = Decoder(output_dim, embedding_dim, hidden_dim, n_layers, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a479fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(enc, dec).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a9c2b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(58101, 256)\n",
       "    (rnn): GRU(256, 1024, num_layers=3, batch_first=True, dropout=0.3)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(58101, 256)\n",
       "    (rnn): GRU(256, 1024, num_layers=3, batch_first=True, dropout=0.3)\n",
       "    (fc_out): Linear(in_features=1024, out_features=58101, bias=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가중치 초기화 함수\n",
    "def init_weights(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            init.constant_(param.data, 0)\n",
    "\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04ddd3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad_idx는 손실 계산에서 무시\n",
    "loss_function = CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "learning_rate = 0.0001\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ef2056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습\n",
    "def train(model, iterator, optimizer, loss_function):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    num_batches = len(iterator)\n",
    "    total_batch_time = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        batch_start_time = time()\n",
    "\n",
    "        # source sequence (x) - english\n",
    "        src = batch['input_ids'].to(device)\n",
    "        # target sequence (y) - germany\n",
    "        trg = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "\n",
    "        # output reshape\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].reshape(-1, output_dim)\n",
    "        \n",
    "        # <sos> 제거 후 target sequence reshape\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "        \n",
    "        loss = loss_function(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # clip (gradient clipping) : gradient explosion 방지 -> 기울기의 크기가 일정 값 이상으로 커지지 않도록 제한\n",
    "        utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        batch_end_time = time()\n",
    "        batch_time = batch_end_time - batch_start_time\n",
    "        total_batch_time += batch_time\n",
    "\n",
    "        batch_mins = int(total_batch_time / 60)\n",
    "        batch_secs = int(total_batch_time% 60)\n",
    "        \n",
    "        if i != 0 and i % 100 == 0:\n",
    "            print(f\"\\t train batch: {i:3d}/{num_batches} \\t loss: {loss.item():.3f} \\t batch_time_for_100 : {batch_mins}m {batch_secs}s\")\n",
    "            total_batch_time = 0\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a6c001e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증\n",
    "def evaluate(model, iterator, loss_function):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    num_batches = len(iterator)\n",
    "    total_batch_time = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            batch_start_time = time()\n",
    "\n",
    "            src = batch['input_ids'].to(device)\n",
    "            trg = batch['labels'].to(device)\n",
    "            \n",
    "            # teacher forcing을 사용하지 않음\n",
    "            output = model(src, trg, 0) \n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[:, 1:].reshape(-1, output_dim)\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = loss_function(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            batch_end_time = time()\n",
    "            batch_time = batch_end_time - batch_start_time\n",
    "            total_batch_time += batch_time\n",
    "\n",
    "        batch_mins = int(total_batch_time / 60)\n",
    "        batch_secs = int(total_batch_time% 60)\n",
    "\n",
    "        print(f\"\\t eval batch: {i:3d}/{num_batches} \\t loss: {loss.item():.3f} \\t batch_time_for_100 : {batch_mins}m {batch_secs}s\")\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0296b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch : 1]\n",
      "\t train batch: 100/640 \t loss: 6.195 \t batch_time_for_100 : 1m 7s\n",
      "\t train batch: 200/640 \t loss: 6.153 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 300/640 \t loss: 6.192 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 400/640 \t loss: 6.150 \t batch_time_for_100 : 1m 7s\n",
      "\t train batch: 500/640 \t loss: 6.167 \t batch_time_for_100 : 1m 7s\n",
      "\t train batch: 600/640 \t loss: 6.156 \t batch_time_for_100 : 1m 5s\n",
      "\t eval batch:  71/72 \t loss: 6.000 \t batch_time_for_100 : 0m 12s\n",
      "epoch:   1/30 \t train ppl: 573.636 val ppl: 472.510 \t 7m 22s \n",
      "\n",
      "[epoch : 2]\n",
      "\t train batch: 100/640 \t loss: 6.124 \t batch_time_for_100 : 1m 7s\n",
      "\t train batch: 200/640 \t loss: 6.118 \t batch_time_for_100 : 1m 7s\n",
      "\t train batch: 300/640 \t loss: 6.095 \t batch_time_for_100 : 1m 7s\n",
      "\t train batch: 400/640 \t loss: 6.175 \t batch_time_for_100 : 1m 7s\n",
      "\t train batch: 500/640 \t loss: 6.178 \t batch_time_for_100 : 1m 7s\n",
      "\t train batch: 600/640 \t loss: 6.277 \t batch_time_for_100 : 1m 6s\n",
      "\t eval batch:  71/72 \t loss: 6.001 \t batch_time_for_100 : 0m 12s\n",
      "epoch:   2/30 \t train ppl: 470.885 val ppl: 466.912 \t 7m 23s \n",
      "\n",
      "[epoch : 3]\n",
      "\t train batch: 100/640 \t loss: 6.123 \t batch_time_for_100 : 1m 7s\n",
      "\t train batch: 200/640 \t loss: 6.156 \t batch_time_for_100 : 1m 7s\n",
      "\t train batch: 300/640 \t loss: 6.134 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 400/640 \t loss: 6.155 \t batch_time_for_100 : 1m 7s\n",
      "\t train batch: 500/640 \t loss: 6.154 \t batch_time_for_100 : 1m 7s\n",
      "\t train batch: 600/640 \t loss: 6.145 \t batch_time_for_100 : 1m 7s\n",
      "\t eval batch:  71/72 \t loss: 6.002 \t batch_time_for_100 : 0m 13s\n",
      "epoch:   3/30 \t train ppl: 466.144 val ppl: 464.693 \t 7m 24s \n",
      "\n",
      "[epoch : 4]\n",
      "\t train batch: 100/640 \t loss: 6.120 \t batch_time_for_100 : 1m 8s\n",
      "\t train batch: 200/640 \t loss: 6.154 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 300/640 \t loss: 6.120 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 400/640 \t loss: 6.192 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 500/640 \t loss: 6.123 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 600/640 \t loss: 6.183 \t batch_time_for_100 : 1m 4s\n",
      "\t eval batch:  71/72 \t loss: 6.001 \t batch_time_for_100 : 0m 12s\n",
      "epoch:   4/30 \t train ppl: 462.917 val ppl: 462.286 \t 7m 17s \n",
      "\n",
      "[epoch : 5]\n",
      "\t train batch: 100/640 \t loss: 6.197 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 200/640 \t loss: 6.119 \t batch_time_for_100 : 1m 4s\n",
      "\t train batch: 300/640 \t loss: 6.164 \t batch_time_for_100 : 1m 4s\n",
      "\t train batch: 400/640 \t loss: 6.130 \t batch_time_for_100 : 1m 4s\n",
      "\t train batch: 500/640 \t loss: 6.177 \t batch_time_for_100 : 1m 4s\n",
      "\t train batch: 600/640 \t loss: 6.089 \t batch_time_for_100 : 1m 4s\n",
      "\t eval batch:  71/72 \t loss: 5.994 \t batch_time_for_100 : 0m 12s\n",
      "epoch:   5/30 \t train ppl: 465.991 val ppl: 456.999 \t 7m 8s \n",
      "\n",
      "[epoch : 6]\n",
      "\t train batch: 100/640 \t loss: 6.163 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 200/640 \t loss: 6.174 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 300/640 \t loss: 6.091 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 400/640 \t loss: 6.074 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 500/640 \t loss: 6.088 \t batch_time_for_100 : 1m 4s\n",
      "\t train batch: 600/640 \t loss: 6.074 \t batch_time_for_100 : 1m 4s\n",
      "\t eval batch:  71/72 \t loss: 6.006 \t batch_time_for_100 : 0m 12s\n",
      "epoch:   6/30 \t train ppl: 453.057 val ppl: 452.219 \t 7m 10s \n",
      "\n",
      "[epoch : 7]\n",
      "\t train batch: 100/640 \t loss: 6.112 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 200/640 \t loss: 6.110 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 300/640 \t loss: 6.097 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 400/640 \t loss: 6.061 \t batch_time_for_100 : 1m 4s\n",
      "\t train batch: 500/640 \t loss: 6.071 \t batch_time_for_100 : 1m 4s\n",
      "\t train batch: 600/640 \t loss: 6.102 \t batch_time_for_100 : 1m 4s\n",
      "\t eval batch:  71/72 \t loss: 5.981 \t batch_time_for_100 : 0m 12s\n",
      "epoch:   7/30 \t train ppl: 447.113 val ppl: 441.275 \t 7m 9s \n",
      "\n",
      "[epoch : 8]\n",
      "\t train batch: 100/640 \t loss: 6.084 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 200/640 \t loss: 6.082 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 300/640 \t loss: 6.169 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 400/640 \t loss: 6.135 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 500/640 \t loss: 6.043 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 600/640 \t loss: 6.002 \t batch_time_for_100 : 1m 4s\n",
      "\t eval batch:  71/72 \t loss: 5.985 \t batch_time_for_100 : 0m 12s\n",
      "epoch:   8/30 \t train ppl: 436.574 val ppl: 433.654 \t 7m 15s \n",
      "\n",
      "[epoch : 9]\n",
      "\t train batch: 100/640 \t loss: 6.059 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 200/640 \t loss: 6.057 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 300/640 \t loss: 6.046 \t batch_time_for_100 : 1m 4s\n",
      "\t train batch: 400/640 \t loss: 6.061 \t batch_time_for_100 : 1m 4s\n",
      "\t train batch: 500/640 \t loss: 6.064 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 600/640 \t loss: 5.968 \t batch_time_for_100 : 1m 4s\n",
      "\t eval batch:  71/72 \t loss: 5.932 \t batch_time_for_100 : 0m 12s\n",
      "epoch:   9/30 \t train ppl: 429.145 val ppl: 416.680 \t 7m 9s \n",
      "\n",
      "[epoch : 10]\n",
      "\t train batch: 100/640 \t loss: 6.040 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 200/640 \t loss: 6.041 \t batch_time_for_100 : 1m 4s\n",
      "\t train batch: 300/640 \t loss: 6.046 \t batch_time_for_100 : 1m 4s\n",
      "\t train batch: 400/640 \t loss: 5.987 \t batch_time_for_100 : 1m 4s\n",
      "\t train batch: 500/640 \t loss: 5.993 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 600/640 \t loss: 5.995 \t batch_time_for_100 : 1m 5s\n",
      "\t eval batch:  71/72 \t loss: 5.907 \t batch_time_for_100 : 0m 12s\n",
      "epoch:  10/30 \t train ppl: 408.713 val ppl: 403.997 \t 7m 9s \n",
      "\n",
      "[epoch : 11]\n",
      "\t train batch: 100/640 \t loss: 5.994 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 200/640 \t loss: 6.034 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 300/640 \t loss: 6.012 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 400/640 \t loss: 6.084 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 500/640 \t loss: 5.941 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 600/640 \t loss: 5.983 \t batch_time_for_100 : 1m 6s\n",
      "\t eval batch:  71/72 \t loss: 5.907 \t batch_time_for_100 : 0m 12s\n",
      "epoch:  11/30 \t train ppl: 396.705 val ppl: 395.271 \t 7m 17s \n",
      "\n",
      "[epoch : 12]\n",
      "\t train batch: 100/640 \t loss: 5.950 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 200/640 \t loss: 6.043 \t batch_time_for_100 : 1m 7s\n",
      "\t train batch: 300/640 \t loss: 5.916 \t batch_time_for_100 : 1m 7s\n",
      "\t train batch: 400/640 \t loss: 5.933 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 500/640 \t loss: 5.917 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 600/640 \t loss: 5.942 \t batch_time_for_100 : 1m 6s\n",
      "\t eval batch:  71/72 \t loss: 5.917 \t batch_time_for_100 : 0m 12s\n",
      "epoch:  12/30 \t train ppl: 385.827 val ppl: 390.503 \t 7m 18s \n",
      "\n",
      "[epoch : 13]\n",
      "\t train batch: 100/640 \t loss: 5.949 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 200/640 \t loss: 5.893 \t batch_time_for_100 : 1m 7s\n",
      "\t train batch: 300/640 \t loss: 5.911 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 400/640 \t loss: 5.909 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 500/640 \t loss: 5.898 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 600/640 \t loss: 5.915 \t batch_time_for_100 : 1m 6s\n",
      "\t eval batch:  71/72 \t loss: 5.904 \t batch_time_for_100 : 0m 13s\n",
      "epoch:  13/30 \t train ppl: 377.081 val ppl: 377.349 \t 7m 20s \n",
      "\n",
      "[epoch : 14]\n",
      "\t train batch: 100/640 \t loss: 5.983 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 200/640 \t loss: 5.870 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 300/640 \t loss: 5.977 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 400/640 \t loss: 5.931 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 500/640 \t loss: 5.813 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 600/640 \t loss: 6.040 \t batch_time_for_100 : 1m 5s\n",
      "\t eval batch:  71/72 \t loss: 5.895 \t batch_time_for_100 : 0m 12s\n",
      "epoch:  14/30 \t train ppl: 368.634 val ppl: 370.660 \t 7m 16s \n",
      "\n",
      "[epoch : 15]\n",
      "\t train batch: 100/640 \t loss: 5.880 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 200/640 \t loss: 5.800 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 300/640 \t loss: 5.903 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 400/640 \t loss: 5.912 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 500/640 \t loss: 5.962 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 600/640 \t loss: 5.859 \t batch_time_for_100 : 1m 6s\n",
      "\t eval batch:  71/72 \t loss: 5.884 \t batch_time_for_100 : 0m 12s\n",
      "epoch:  15/30 \t train ppl: 359.307 val ppl: 371.388 \t 7m 16s \n",
      "\n",
      "[epoch : 16]\n",
      "\t train batch: 100/640 \t loss: 5.822 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 200/640 \t loss: 5.811 \t batch_time_for_100 : 1m 4s\n",
      "\t train batch: 300/640 \t loss: 5.772 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 400/640 \t loss: 5.695 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 500/640 \t loss: 5.624 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 600/640 \t loss: 5.743 \t batch_time_for_100 : 1m 6s\n",
      "\t eval batch:  71/72 \t loss: 5.982 \t batch_time_for_100 : 0m 12s\n",
      "epoch:  16/30 \t train ppl: 319.292 val ppl: 387.143 \t 7m 14s \n",
      "\n",
      "[epoch : 17]\n",
      "\t train batch: 100/640 \t loss: 5.673 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 200/640 \t loss: 5.691 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 300/640 \t loss: 5.665 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 400/640 \t loss: 5.555 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 500/640 \t loss: 5.687 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 600/640 \t loss: 5.474 \t batch_time_for_100 : 1m 5s\n",
      "\t eval batch:  71/72 \t loss: 5.876 \t batch_time_for_100 : 0m 12s\n",
      "epoch:  17/30 \t train ppl: 281.835 val ppl: 372.511 \t 7m 13s \n",
      "\n",
      "[epoch : 18]\n",
      "\t train batch: 100/640 \t loss: 5.611 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 200/640 \t loss: 5.670 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 300/640 \t loss: 5.503 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 400/640 \t loss: 5.475 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 500/640 \t loss: 5.596 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 600/640 \t loss: 5.540 \t batch_time_for_100 : 1m 4s\n",
      "\t eval batch:  71/72 \t loss: 5.915 \t batch_time_for_100 : 0m 12s\n",
      "epoch:  18/30 \t train ppl: 258.608 val ppl: 367.286 \t 7m 13s \n",
      "\n",
      "[epoch : 19]\n",
      "\t train batch: 100/640 \t loss: 5.448 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 200/640 \t loss: 5.480 \t batch_time_for_100 : 1m 4s\n",
      "\t train batch: 300/640 \t loss: 5.474 \t batch_time_for_100 : 1m 4s\n",
      "\t train batch: 400/640 \t loss: 5.588 \t batch_time_for_100 : 1m 4s\n",
      "\t train batch: 500/640 \t loss: 5.511 \t batch_time_for_100 : 1m 4s\n",
      "\t train batch: 600/640 \t loss: 5.243 \t batch_time_for_100 : 1m 4s\n",
      "\t eval batch:  71/72 \t loss: 5.900 \t batch_time_for_100 : 0m 12s\n",
      "epoch:  19/30 \t train ppl: 231.665 val ppl: 368.486 \t 7m 6s \n",
      "\n",
      "[epoch : 20]\n",
      "\t train batch: 100/640 \t loss: 5.497 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 200/640 \t loss: 5.368 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 300/640 \t loss: 5.333 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 400/640 \t loss: 5.278 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 500/640 \t loss: 5.366 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 600/640 \t loss: 5.226 \t batch_time_for_100 : 1m 5s\n",
      "\t eval batch:  71/72 \t loss: 5.994 \t batch_time_for_100 : 0m 12s\n",
      "epoch:  20/30 \t train ppl: 204.329 val ppl: 364.735 \t 7m 13s \n",
      "\n",
      "[epoch : 21]\n",
      "\t train batch: 100/640 \t loss: 5.221 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 200/640 \t loss: 5.304 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 300/640 \t loss: 5.213 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 400/640 \t loss: 5.138 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 500/640 \t loss: 5.155 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 600/640 \t loss: 5.325 \t batch_time_for_100 : 1m 5s\n",
      "\t eval batch:  71/72 \t loss: 5.959 \t batch_time_for_100 : 0m 12s\n",
      "epoch:  21/30 \t train ppl: 181.601 val ppl: 370.584 \t 7m 16s \n",
      "\n",
      "[epoch : 22]\n",
      "\t train batch: 100/640 \t loss: 5.061 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 200/640 \t loss: 5.004 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 300/640 \t loss: 5.083 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 400/640 \t loss: 5.256 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 500/640 \t loss: 4.951 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 600/640 \t loss: 4.927 \t batch_time_for_100 : 1m 6s\n",
      "\t eval batch:  71/72 \t loss: 5.917 \t batch_time_for_100 : 0m 12s\n",
      "epoch:  22/30 \t train ppl: 163.957 val ppl: 375.324 \t 7m 18s \n",
      "\n",
      "[epoch : 23]\n",
      "\t train batch: 100/640 \t loss: 5.182 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 200/640 \t loss: 5.109 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 300/640 \t loss: 4.877 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 400/640 \t loss: 5.236 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 500/640 \t loss: 5.100 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 600/640 \t loss: 5.099 \t batch_time_for_100 : 1m 5s\n",
      "\t eval batch:  71/72 \t loss: 5.947 \t batch_time_for_100 : 0m 12s\n",
      "epoch:  23/30 \t train ppl: 151.030 val ppl: 391.539 \t 7m 17s \n",
      "\n",
      "[epoch : 24]\n",
      "\t train batch: 100/640 \t loss: 4.889 \t batch_time_for_100 : 1m 7s\n",
      "\t train batch: 200/640 \t loss: 4.908 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 300/640 \t loss: 4.920 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 400/640 \t loss: 4.978 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 500/640 \t loss: 5.122 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 600/640 \t loss: 4.931 \t batch_time_for_100 : 1m 6s\n",
      "\t eval batch:  71/72 \t loss: 5.928 \t batch_time_for_100 : 0m 12s\n",
      "epoch:  24/30 \t train ppl: 143.951 val ppl: 367.067 \t 7m 18s \n",
      "\n",
      "[epoch : 25]\n",
      "\t train batch: 100/640 \t loss: 5.053 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 200/640 \t loss: 4.798 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 300/640 \t loss: 5.080 \t batch_time_for_100 : 1m 4s\n",
      "\t train batch: 400/640 \t loss: 4.763 \t batch_time_for_100 : 1m 4s\n",
      "\t train batch: 500/640 \t loss: 4.922 \t batch_time_for_100 : 1m 4s\n",
      "\t train batch: 600/640 \t loss: 4.852 \t batch_time_for_100 : 1m 4s\n",
      "\t eval batch:  71/72 \t loss: 5.942 \t batch_time_for_100 : 0m 12s\n",
      "epoch:  25/30 \t train ppl: 133.397 val ppl: 372.401 \t 7m 12s \n",
      "\n",
      "[epoch : 26]\n",
      "\t train batch: 100/640 \t loss: 4.788 \t batch_time_for_100 : 1m 7s\n",
      "\t train batch: 200/640 \t loss: 4.752 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 300/640 \t loss: 4.811 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 400/640 \t loss: 4.995 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 500/640 \t loss: 4.632 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 600/640 \t loss: 4.765 \t batch_time_for_100 : 1m 6s\n",
      "\t eval batch:  71/72 \t loss: 5.875 \t batch_time_for_100 : 0m 12s\n",
      "epoch:  26/30 \t train ppl: 126.801 val ppl: 370.778 \t 7m 21s \n",
      "\n",
      "[epoch : 27]\n",
      "\t train batch: 100/640 \t loss: 4.778 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 200/640 \t loss: 4.636 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 300/640 \t loss: 4.879 \t batch_time_for_100 : 1m 7s\n",
      "\t train batch: 400/640 \t loss: 4.928 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 500/640 \t loss: 5.116 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 600/640 \t loss: 4.759 \t batch_time_for_100 : 1m 6s\n",
      "\t eval batch:  71/72 \t loss: 5.894 \t batch_time_for_100 : 0m 12s\n",
      "epoch:  27/30 \t train ppl: 120.649 val ppl: 376.358 \t 7m 20s \n",
      "\n",
      "[epoch : 28]\n",
      "\t train batch: 100/640 \t loss: 4.743 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 200/640 \t loss: 4.671 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 300/640 \t loss: 4.611 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 400/640 \t loss: 4.604 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 500/640 \t loss: 4.734 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 600/640 \t loss: 4.659 \t batch_time_for_100 : 1m 6s\n",
      "\t eval batch:  71/72 \t loss: 5.932 \t batch_time_for_100 : 0m 12s\n",
      "epoch:  28/30 \t train ppl: 115.357 val ppl: 373.816 \t 7m 19s \n",
      "\n",
      "[epoch : 29]\n",
      "\t train batch: 100/640 \t loss: 4.903 \t batch_time_for_100 : 1m 8s\n",
      "\t train batch: 200/640 \t loss: 4.640 \t batch_time_for_100 : 1m 6s\n",
      "\t train batch: 300/640 \t loss: 4.607 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 400/640 \t loss: 4.701 \t batch_time_for_100 : 1m 4s\n",
      "\t train batch: 500/640 \t loss: 4.723 \t batch_time_for_100 : 1m 4s\n",
      "\t train batch: 600/640 \t loss: 4.686 \t batch_time_for_100 : 1m 4s\n",
      "\t eval batch:  71/72 \t loss: 5.907 \t batch_time_for_100 : 0m 12s\n",
      "epoch:  29/30 \t train ppl: 110.765 val ppl: 355.731 \t 7m 12s \n",
      "\n",
      "[epoch : 30]\n",
      "\t train batch: 100/640 \t loss: 4.653 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 200/640 \t loss: 4.706 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 300/640 \t loss: 4.483 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 400/640 \t loss: 4.625 \t batch_time_for_100 : 1m 4s\n",
      "\t train batch: 500/640 \t loss: 4.530 \t batch_time_for_100 : 1m 5s\n",
      "\t train batch: 600/640 \t loss: 4.638 \t batch_time_for_100 : 1m 6s\n",
      "\t eval batch:  71/72 \t loss: 5.914 \t batch_time_for_100 : 0m 12s\n",
      "epoch:  30/30 \t train ppl: 105.278 val ppl: 380.002 \t 7m 13s \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "\n",
    "total_time = 0\n",
    "\n",
    "for epoch in range(1,epochs+1):\n",
    "    print(f\"[epoch : {epoch}]\")\n",
    "    start_time = time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, loss_function)\n",
    "    valid_loss = evaluate(model, valid_iterator, loss_function)\n",
    "    \n",
    "    # Perplexity (PPL): 낮을수록 좋음. exp(loss) -> 모델이 예측한 확률 분포에 대한 불확실성을 측정\n",
    "    train_ppl = math.exp(train_loss)\n",
    "    valid_ppl = math.exp(valid_loss)\n",
    "\n",
    "    end_time = time()\n",
    "\n",
    "    epoch_time = end_time - start_time\n",
    "    total_time += epoch_time\n",
    "    \n",
    "    epoch_mins = int((epoch_time) / 60)\n",
    "    epoch_secs = int((epoch_time) % 60)\n",
    "\n",
    "    print(f\"epoch: {epoch:3d}/{epochs} \\t train ppl: {train_ppl:4.3f} val ppl: {valid_ppl:4.3f} \\t {epoch_mins}m {epoch_secs}s \\n\")\n",
    "\n",
    "print(f\"\\ntotal time : {total_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "244d954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_translation(model, sentence, tokenizer, max_len=64):\n",
    "    model.eval()\n",
    "\n",
    "    # pt : pytorch\n",
    "    tokenized = tokenizer(sentence, return_tensors='pt', truncation=True)\n",
    "\n",
    "    src = tokenized['input_ids'].to(device)\n",
    "\n",
    "    # <sos> token (시작)\n",
    "    sos_token_id = tokenizer.pad_token_id\n",
    "    \n",
    "    # decoder의 첫 input token id\n",
    "    input_token = torch.tensor([sos_token_id], dtype=torch.long, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden = model.encoder(src)\n",
    "\n",
    "    # 번역된 token 저장\n",
    "    translated_tokens = []\n",
    "\n",
    "    # greedy decoding : 한 번에 하나의 토큰을 생성하며 문장을 완성\n",
    "    for _ in range(max_len):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, hidden = model.decoder(input_token, hidden)\n",
    "\n",
    "        # 가장 높은 확률을 가진 token의 id\n",
    "        next_token_id = output.argmax(1).item()\n",
    "\n",
    "        # 예측된 token이 <eos> 거나 <pad> 이면 종료\n",
    "        if next_token_id == tokenizer.eos_token_id or next_token_id == tokenizer.pad_token_id:\n",
    "            # 첫 토큰이 <eos>인 경우 제외\n",
    "            if len(translated_tokens) > 0:\n",
    "                break\n",
    "\n",
    "        # 결과 token 저장\n",
    "        translated_tokens.append(next_token_id)\n",
    "\n",
    "        # 현재 token은 다음 시점의 input\n",
    "        input_token = torch.tensor([next_token_id], dtype=torch.long, device=device)\n",
    "\n",
    "    # 사람이 읽을 수 있는 단어로 변환\n",
    "    # skip_special_tokens=True : <eos>, <pad> 같은 token들은 skip\n",
    "    translated_sentence = tokenizer.decode(translated_tokens, skip_special_tokens=True)\n",
    "    \n",
    "    return translated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1914071c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sequence: I am happy. Because studing is hard.\n",
      "output sequence: eserdem dert,t,t,t\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"I am happy. Because studing is hard.\" \n",
    "\n",
    "predicted_translation = predict_translation(model, test_sentence, tokenizer)\n",
    "\n",
    "print(f\"input sequence: {test_sentence}\")\n",
    "print(f\"output sequence: {predicted_translation}\")\n",
    "# 제대로 학습되었다면 : Ich bin glücklich. Denn das Studium ist anstrengend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9131efec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
